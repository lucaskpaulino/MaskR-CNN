{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Mask Detectron - LVIS",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucaskpaulino/MaskR-CNN/blob/main/Mask_Detectron_LVIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1o6QZr-6TnR"
      },
      "source": [
        "## Instalação do Detectron 2 \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "São instaladas primeiramente suas dependências e em seguida o detectron\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vA_vhkDsvpu"
      },
      "source": [
        "funçãão anti-afk colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR"
      },
      "source": [
        "# install dependencies: \n",
        "!pip install pyyaml==5.1\n",
        "!pip install imantics\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab\n",
        "# Helper function, used these for debugging purposes\n",
        "# detector2 build only succeeds if CUDA version is correct\n",
        "\n",
        "#!nvidia-smi\n",
        "#!nvcc --version\n",
        "\n",
        "#import torch\n",
        "#torch.__version__\n",
        "#import torchvision\n",
        "#torchvision.__version__\n",
        "\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihrXyYK6dSbq"
      },
      "source": [
        "#!pip install -q -U torch torchvision -f https://download.pytorch.org/whl/torch_stable.html \n",
        "#!pip install -q -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "#!pip install -q detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cpu/index.html\n",
        "!pip install git+https://github.com/lvis-dataset/lvis-api.git\n",
        "!pip install \"git+https://github.com/philferriere/cocoapi.git#egg=pycocotools&subdirectory=PythonAPI\"\n",
        "!pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcnKpfZVhTS3"
      },
      "source": [
        "**Importações necessárias para rodar o detectron2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "source": [
        "\n",
        "# Base setup:\n",
        "# detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.structures import BoxMode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxAiLUWWhiyq"
      },
      "source": [
        "# **Comando para visualizar a placa de vídeo disponibilizada pelo Colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fec3qxl70FC"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZTuZSHL_9N1"
      },
      "source": [
        "## Importar e resgistrar Dataset\n",
        "\n",
        "\n",
        "---\n",
        "Aqui será utilizado o Dataset Cityscapes\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxZYmJD8AmAB"
      },
      "source": [
        "## Treinamento\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf_nepf4mV7U"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4UESNQ4tyVm"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.engine.hooks import HookBase\n",
        "from detectron2.evaluation import inference_context\n",
        "from detectron2.utils.logger import log_every_n_seconds\n",
        "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
        "import detectron2.utils.comm as comm\n",
        "import torch\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "class MyTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
        "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
        "                     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV0k4nIjh1CF"
      },
      "source": [
        "**Aqui é criado um hook (gancho), que é responsável pela critério de parada (Early stopping)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m6zY2okMg77"
      },
      "source": [
        "def build_hooks(self):\n",
        "        hooks = super().build_hooks()\n",
        "        hooks.insert(-1,LossEvalHook(\n",
        "            cfg.TEST.EVAL_PERIOD,\n",
        "            self.model,\n",
        "            build_detection_test_loader(\n",
        "                self.cfg,\n",
        "                self.cfg.DATASETS.TEST[0],\n",
        "                DatasetMapper(self.cfg,True)\n",
        "            )\n",
        "        ))\n",
        "        return hooks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6io4CpIcfSvi"
      },
      "source": [
        "class LossEvalHook(HookBase):\n",
        "   \n",
        "      def __init__(self, eval_period, model, data_loader):\n",
        "        self._model = model\n",
        "        self._period = eval_period\n",
        "        self._data_loader = data_loader\n",
        "    \n",
        "      def _do_loss_eval(self):\n",
        "        # Copying inference_on_dataset from evaluator.py\n",
        "        total = len(self._data_loader)\n",
        "        num_warmup = min(5, total - 1)\n",
        "            \n",
        "        start_time = time.perf_counter()\n",
        "        total_compute_time = 0\n",
        "        losses = []\n",
        "        for idx, inputs in enumerate(self._data_loader):            \n",
        "            if idx == num_warmup:\n",
        "                start_time = time.perf_counter()\n",
        "                total_compute_time = 0\n",
        "            start_compute_time = time.perf_counter()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.synchronize()\n",
        "            total_compute_time += time.perf_counter() - start_compute_time\n",
        "            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n",
        "            seconds_per_img = total_compute_time / iters_after_start\n",
        "            if idx >= num_warmup * 2 or seconds_per_img > 5:\n",
        "                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n",
        "                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n",
        "                log_every_n_seconds(\n",
        "                    logging.INFO,\n",
        "                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n",
        "                        idx + 1, total, seconds_per_img, str(eta)\n",
        "                    ),\n",
        "                    n=5,\n",
        "                )\n",
        "            loss_batch = self._get_loss(inputs)\n",
        "            losses.append(loss_batch)\n",
        "        mean_loss = np.mean(losses)\n",
        "        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n",
        "        comm.synchronize()\n",
        "\n",
        "        return losses\n",
        "            \n",
        "        def _get_loss(self, data):\n",
        "        # How loss is calculated on train_loop \n",
        "          metrics_dict = self._model(data)\n",
        "          metrics_dict = {\n",
        "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
        "            for k, v in metrics_dict.items()\n",
        "          }\n",
        "          total_losses_reduced = sum(loss for loss in metrics_dict.values())\n",
        "        return total_losses_reduced\n",
        "        \n",
        "        \n",
        "        def after_step(self):\n",
        "          next_iter = self.trainer.iter + 1\n",
        "          is_final = next_iter == self.trainer.max_iter\n",
        "          if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
        "              self._do_loss_eval()\n",
        "          self.trainer.storage.put_scalars(timetest=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLqPctTyiOOz"
      },
      "source": [
        "# **Definição dos parâmetros e treinamento**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XWI0WS0hqLg"
      },
      "source": [
        "%mkdir datasets\n",
        "%mkdir datasets/lvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ6XFyP0k20E"
      },
      "source": [
        "import gdown\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1wcf6wb_RpYUqyZgsEa2eIrEIDrohsBQ9\n",
        "!gdown https://drive.google.com/uc?id=1JDlvKip1PlgSRbR8msWxMXfu93-TdFLa\n",
        "\n",
        "!unzip \"lvis_v1_train.json.zip\" -d \"datasets/lvis\"\n",
        "!unzip \"lvis_v1_val.json.zip\" -d \"datasets/lvis\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRNkFGfKtIKg"
      },
      "source": [
        "!unzip \"lvis_v1_image_info_test_dev.zip\" -d \"datasets/lvis\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTr4OO-665dU"
      },
      "source": [
        "%mkdir datasets/coco"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZqAL8NKKzNH"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOlNLaI-era_"
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/train2017.zip\n",
        "!unzip \"train2017.zip\" -d \"/content/datasets/coco\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsqULTGrFLXf"
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/val2017.zip\n",
        "!unzip \"val2017.zip\" -d \"/content/datasets/coco\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLRUYSH0jbxR"
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/test2017.zip\n",
        "!unzip \"test2017.zip\" -d \"/content/datasets/coco\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpVLK8mho1yp"
      },
      "source": [
        "#from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "#register_coco_instances(\"lucas_val1\", {}, \"coco-1634746569.6402342.json\", \"/content/datasets/coco/val2017\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd9helx_r81_"
      },
      "source": [
        "#from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "#register_coco_instances(\"lucas_val1\", {}, \"coco-1634746569.6402342.json\", \"/content/datasets/coco/val2017\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "34BP2JWwbym5"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "#from lvis import LVIS\n",
        "\n",
        "from tensorflow import data\n",
        "#AUTOTUNE = data.experimental.AUTOTUNE\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"))\n",
        "\n",
        "cfg.DATASETS.TRAIN = (\"lvis_v1_train\",)\n",
        "cfg.DATASETS.TEST = (\"lvis_v1_val\",)\n",
        "\n",
        "cfg.SOLVER.REFERENCEWORLDSIZE = 1\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\")  # Let training initialize from model zoo\n",
        "\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4\n",
        "cfg.SOLVER.BASE_LR = 0.00001  # learning rate\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 1024 # default 512\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1203\n",
        "\n",
        "cfg.SOLVER.WARMUP_ITERS = 50\n",
        "cfg.SOLVER.MAX_ITER = 600 # 1500 ajustar para overfit ou mAP subindo\n",
        "\n",
        "cfg.SOLVER.STEPS = (300,500) #1000, 1500\n",
        "cfg.SOLVER.GAMMA = 0.005\n",
        "\n",
        "cfg.TEST.EVAL_PERIOD = 400\n",
        "\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 200\n",
        "\n",
        "\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = MyTrainer(cfg)\n",
        "#trainer.resume_or_load(resume=True)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txylQMSVljY7"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBXeH8UXFcqU"
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output\n",
        "#!kill 640"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpu4-aZW7LUq"
      },
      "source": [
        "def rle_decode(data):\n",
        "    decode = ''\n",
        "    count = ''\n",
        "    for char in data:\n",
        "        # If the character is numerical...\n",
        "        if char.isdigit():\n",
        "            # ...append it to our count\n",
        "            count += char\n",
        "        else:\n",
        "            # Otherwise we've seen a non-numerical\n",
        "            # character and need to expand it for\n",
        "            # the decoding\n",
        "            decode += char * int(count)\n",
        "            count = ''\n",
        "    return decode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mClCEwQ_XNom"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('/content/PKLot/PKLot/instances_ufpr05_test.json') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "    #print(json_data['annotations'])\n",
        "data = json.dumps(json_data)\n",
        "\n",
        "for annotations in json_data['annotations']:\n",
        "  print(annotations['image_id'],annotations['segmentation'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-I1ERE9MK2_"
      },
      "source": [
        "import json\n",
        "import pycocotools\n",
        "import numpy as np\n",
        "from imantics import Polygons, Mask\n",
        "import pycocotools.mask as mask_util\n",
        "from detectron2 import structures\n",
        "\n",
        "\n",
        "\n",
        "with open('/content/PKLot/PKLot/output/inference/coco_instances_results.json') as json_predict:\n",
        "    json_p = json.load(json_predict)\n",
        "    #print(json_data)\n",
        "    #print(json.dumps(json_data[1], indent=4))\n",
        "\n",
        "data_p = json.dumps(json_p)\n",
        "data2_p = json.loads(data_p)\n",
        "\n",
        "with open('/content/PKLot/PKLot/instances_ufpr05_test.json') as json_gt:\n",
        "    json_gt = json.load(json_gt)\n",
        "    #print(json_data['annotations'])\n",
        "\n",
        "data_gt = json.dumps(json_gt)\n",
        "data2_gt = json.loads(data_gt)\n",
        "\n",
        "\n",
        "for counts, annotations in zip(data2_p, data2_gt['annotations']):\n",
        "  \n",
        "  #for annotations in data2_gt['annotations']:\n",
        "   # print(annotations['image_id'],annotations['segmentation'])\n",
        "  #counts['image_id'],\n",
        "    seg_mask = ( counts['segmentation'])\n",
        "    mask = mask_util.decode(seg_mask)[:, :]\n",
        "  \n",
        "    polygons = Mask(mask).polygons()\n",
        "   # if data2_gt[counts] =! 1:\n",
        "    #print(counts['image_id'], polygons.segmentation)  \n",
        "    #print(annotations['image_id'])\n",
        "    if counts['image_id'] == annotations['image_id']:\n",
        "      bboxes_gt = polygons.segmentation\n",
        "      bboxes_pred = annotations['segmentation']\n",
        "      #polygon_area(bboxes_gt, bboxes_pred)\n",
        "      #IOUs = structures.pairwise_iou(bboxes_gt, bboxes_pred)\n",
        "      print(bboxes_gt)\n",
        "      print(bboxes_pred)\n",
        "    #print(mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E0keBL6pIfm"
      },
      "source": [
        "def polygon_area(x, y):\n",
        "    # Using the shoelace formula\n",
        "    # https://stackoverflow.com/questions/24467972/calculate-area-of-polygon-given-x-y-coordinates\n",
        "    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqo_g1L8aGcB"
      },
      "source": [
        "import json\n",
        "import pycocotools\n",
        "import numpy as np\n",
        "from imantics import Polygons, Mask\n",
        "import pycocotools.mask as mask_util\n",
        "\n",
        "with open('/content/PKLot/PKLot/output/inference/coco_instances_results.json') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "    #print(json_data)\n",
        "    #print(json.dumps(json_data[1], indent=4))\n",
        "\n",
        "data = json.dumps(json_data)\n",
        "\n",
        "data2 = json.loads(data)\n",
        "\n",
        "for counts in data2:\n",
        "  #counts['image_id'],\n",
        "  seg_mask = ( counts['segmentation'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OM4AA-flw5U"
      },
      "source": [
        "def get_building_dicts(img_dir):\n",
        "    \"\"\"This function loads the JSON file created with the annotator and converts it to\n",
        "    the detectron2 metadata specifications.\n",
        "    \"\"\"\n",
        "    # load the JSON file\n",
        "    json_file = os.path.join(img_dir, \"/content/PKLot/PKLot/instances_pucpr_train.json\")\n",
        "    with open(json_file) as f:\n",
        "        imgs_anns = json.load(f)\n",
        "\n",
        "    dataset_dicts = []\n",
        "    # loop through the entries in the JSON file\n",
        "    for idx, v in enumerate(imgs_anns.values()):\n",
        "        record = {}\n",
        "        # add file_name, image_id, height and width information to the records\n",
        "        filename = os.path.join(img_dir, v[\"filename\"])\n",
        "        height, width = cv2.imread(filename).shape[:2]\n",
        "\n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "\n",
        "        annos = v[\"regions\"]\n",
        "\n",
        "        objs = []\n",
        "        # one image can have multiple annotations, therefore this loop is needed\n",
        "        for annotation in annos:\n",
        "            # reformat the polygon information to fit the specifications\n",
        "            anno = annotation[\"shape_attributes\"]\n",
        "            px = anno[\"all_points_x\"]\n",
        "            py = anno[\"all_points_y\"]\n",
        "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
        "            poly = [p for x in poly for p in x]\n",
        "\n",
        "            region_attributes = annotation[\"region_attributes\"][\"class\"]\n",
        "\n",
        "            # specify the category_id to match with the class.\n",
        "\n",
        "            if \"building\" in region_attributes:\n",
        "                category_id = 1\n",
        "            elif \"window\" in region_attributes:\n",
        "                category_id = 0\n",
        "\n",
        "            obj = {\n",
        "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": [poly],\n",
        "                \"category_id\": category_id,\n",
        "                \"iscrowd\": 0,\n",
        "            }\n",
        "            objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "\n",
        "    return dataset_dicts\n",
        "\n",
        "\n",
        "    # the data has to be registered within detectron2, once for the train and once for\n",
        "# the val data\n",
        "#for d in [\"train\", \"val\"]:\n",
        " #   DatasetCatalog.register(\n",
        " #       \"buildings_\" + d,\n",
        " #       lambda d=d: get_building_dicts(\"/content/\" + d),\n",
        " #   )\n",
        "\n",
        "building_metadata = MetadataCatalog.get(\"buildings_train\")\n",
        "\n",
        "dataset_dicts = get_building_dicts(\"/content/train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pYiRYNVEioy"
      },
      "source": [
        "## Teste de validação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk9YJjz4UTC8"
      },
      "source": [
        "!sudo pip install -U numpy==1.11.0.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBUdNVhn1rHh"
      },
      "source": [
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "cfg = get_cfg()\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"/content/output/model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.50\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"lvis_v1_train\", cfg, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"lvis_v1_train\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "#instances_to_coco_json(instances, img_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI4nwe8s0QaG"
      },
      "source": [
        "visualizar as inferências\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaWA6UPd1mFT"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataset_dicts = DatasetCatalog.get('PKLot_test2')\n",
        "for d in random.sample(dataset_dicts, 5):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1], metadata=MetadataCatalog.get(dataset_dicts), scale=0.8)\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.figure(figsize = (14, 10))\n",
        "    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu0-gm_AEMSP"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXxvI6tsEU8Y"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSRM_-reEH0t"
      },
      "source": [
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
        "im = cv2.imread(\"/content/datasets/coco/val2017/000000000139.jpg\")\n",
        "cv2_imshow(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKctu6rTEcqO"
      },
      "source": [
        "cfg = get_cfg()\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg)\n",
        "outputs = predictor(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3obWe5EEg8e"
      },
      "source": [
        "# look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n",
        "print(outputs[\"instances\"].pred_classes)\n",
        "print(outputs[\"instances\"].pred_boxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-FJJf6p5sUy"
      },
      "source": [
        "#outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\n",
        "#outputs[\"instances\"].pred_classes.cpu().numpy()\n",
        "print(outputs[\"instances\"].pred_boxes.tensor.cpu().numpy())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR2QHgI7Ej1g"
      },
      "source": [
        "# We can use `Visualizer` to draw the predictions on the image.\n",
        "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUFLnjDnO0Dx"
      },
      "source": [
        "def convert_to_coco_json(dataset_name, output_file, allow_cached=True):\n",
        "    \"\"\"\n",
        "    Converts dataset into COCO format and saves it to a json file.\n",
        "    dataset_name must be registered in DatasetCatalog and in detectron2's standard format.\n",
        "\n",
        "    Args:\n",
        "        dataset_name:\n",
        "            reference from the config file to the catalogs\n",
        "            must be registered in DatasetCatalog and in detectron2's standard format\n",
        "        output_file: path of json file that will be saved to\n",
        "        allow_cached: if json file is already present then skip conversion\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: The dataset or the conversion script *may* change,\n",
        "    # a checksum would be useful for validating the cached data\n",
        "\n",
        "    PathManager.mkdirs(os.path.dirname(output_file))\n",
        "    with file_lock(output_file):\n",
        "        if PathManager.exists(output_file) and allow_cached:\n",
        "            logger.warning(\n",
        "                f\"Using previously cached COCO format annotations at '{output_file}'. \"\n",
        "                \"You need to clear the cache file if your dataset has been modified.\"\n",
        "            )\n",
        "        else:\n",
        "            logger.info(f\"Converting annotations of dataset '{PKLot_test}' to COCO format ...)\")\n",
        "            coco_dict = convert_to_coco_dict(PKLot_test)\n",
        "\n",
        "            logger.info(f\"Caching COCO format annotations at '{output_file}' ...\")\n",
        "            tmp_file = output_file + \".tmp\"\n",
        "            with PathManager.open(tmp_file, \"w\") as f:\n",
        "                json.dump(coco_dict, f)\n",
        "            shutil.move(tmp_file, output_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItVFJAF_cQDg"
      },
      "source": [
        "from detectron2.data.datasets.coco import convert_to_coco_json\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "def data_dict():\n",
        "    return [{\n",
        "        'file_name': 'image.png',\n",
        "        'image_id': 'image',\n",
        "        'validated': 'false',\n",
        "        'height': 100,\n",
        "        'width': 100,\n",
        "        'annotations': [{\n",
        "            'bbox': [70, 30, 100, 70],\n",
        "            ## area should be 30*40=1200\n",
        "            'bbox_mode': BoxMode.XYXY_ABS,\n",
        "            'category_id': 1,\n",
        "            'iscrowd': 0,\n",
        "        }]\n",
        "    }]\n",
        "\n",
        "def to_json():\n",
        "    #cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "   # cfg.DATASETS.TEST = (\"PKLot_test\")\n",
        "   # cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
        "   # predictor = DefaultPredictor(cfg)\n",
        "   # test_metadata = MetadataCatalog.get(\"PKLot_test\")\n",
        "   # register_coco_instances(\"pk_json4\", {}, \"output/coco_instances_results.json\", \"output/\")\n",
        "    #DatasetCatalog.register('pk_json3', data_dict)\n",
        "   # MetadataCatalog.get('PKLot_test').set(thing_classes=[\"car\"])\n",
        "    #convert_to_coco_json('test_metadata', output_file='./output/test.json', allow_cached=False)\n",
        "\n",
        "    #DatasetCatalog.register('test2', data_dict)\n",
        "    MetadataCatalog.get('PKLot_test').set(thing_classes=[\"car\"])\n",
        "    convert_to_coco_json('PKLot_test', output_file='./output/test4.json', allow_cached=False)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    to_json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZXn3zMtXI5a"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('output/test4.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0A8XX9v0Ev-"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from detectron2.structures import Instances, pairwise_iou_rotated, RotatedBoxes\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "boxes1 = torch.tensor([[160.0, 153.0, 230.0,  23.0, -37.0]], device='cuda')\n",
        "boxes2 = torch.tensor([[190.0, 127.0,  80.0,  21.0, -46.0]], device='cuda')\n",
        "print(pairwise_iou_rotated(RotatedBoxes(boxes1), RotatedBoxes(boxes2)))\n",
        "\n",
        "instances = Instances((300, 300))\n",
        "instances.pred_boxes = torch.cat((boxes1, boxes2)).cpu()\n",
        "instances.scores = torch.tensor([1.0, 1.0])\n",
        "instances.pred_classes = torch.tensor([0, 0])\n",
        "\n",
        "viz = Visualizer(np.full((300, 300, 3), 127, dtype=np.uint8), {'thing_classes': ['thing']})\n",
        "image = viz.draw_instance_predictions(instances).get_image()[:, :, ::-1]\n",
        "cv2.imwrite('out.png', image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpD7jmLEFUEz"
      },
      "source": [
        "## Inferência e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImtN8p4H6b-p"
      },
      "source": [
        "im = cv2.imread(\"/content/PKLot/PKLot/UFPR05/Sunny/2013-02-22/2013-02-22_08_15_02.jpg\")\n",
        "cv2_imshow(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IRGo8d0qkgR"
      },
      "source": [
        "# We can use `Visualizer` to draw the predictions on the image.\n",
        "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\n",
        "outputs[\"instances\"].pred_classes.cpu().numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8te2HiuSNyt"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "test_metadata = MetadataCatalog.get(\"PKLot_test2\")\n",
        "dataset_dicts = DatasetCatalog.get('PKLot_test2')\n",
        "for d in random.sample(dataset_dicts, 5):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1], metadata=test_metadata, scale=0.8)\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.figure(figsize = (14, 10))\n",
        "    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiJ0Ylc_XAUa"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "import glob\n",
        "\n",
        "for imageName in glob.glob('/content/test/*jpg'):\n",
        "  im = cv2.imread(imageName)\n",
        "  outputs = predictor(im)\n",
        "  v = Visualizer(im[:, :, ::-1],\n",
        "                metadata=test_metadata, \n",
        "                scale=0.8\n",
        "                 )\n",
        "  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "  cv2_imshow(out.get_image()[:, :, ::-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxRHYcAC_Z0f"
      },
      "source": [
        "import time\n",
        "times = []\n",
        "for i in range(20):\n",
        "    start_time = time.time()\n",
        "    outputs = predictor(im)\n",
        "    delta = time.time() - start_time\n",
        "    times.append(delta)\n",
        "mean_delta = np.array(times).mean()\n",
        "fps = 1 / mean_delta\n",
        "print(\"Average(sec):{:.2f},fps:{:.2f}\".format(mean_delta, fps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJiG0LgxQtaz"
      },
      "source": [
        "#%cd facebook/detectron2/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}